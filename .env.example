# LLM Provider Configuration
DOCPILOT_LLM_PROVIDER=openai  # openai, anthropic, local, mock
DOCPILOT_LLM_MODEL=gpt-4
DOCPILOT_LLM_TEMPERATURE=0.3

# OpenAI Configuration
OPENAI_API_KEY=your-api-key-here
OPENAI_ORG_ID=your-org-id  # Optional

# Anthropic Configuration
ANTHROPIC_API_KEY=your-api-key-here

# Ollama Configuration (local)
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=codellama

# Output Configuration
DOCPILOT_STYLE=google  # google, numpy, sphinx
DOCPILOT_MIN_COVERAGE=80

# Logging
DOCPILOT_LOG_LEVEL=INFO  # DEBUG, INFO, WARNING, ERROR
DOCPILOT_LOG_FORMAT=json  # json, text

# Cache Configuration
DOCPILOT_CACHE_DIR=.docpilot_cache
DOCPILOT_CACHE_TTL=3600  # seconds
